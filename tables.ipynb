{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">score:accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>eval_split</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>output_prob_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">gpt2-xl</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">agnews</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>content_free_['[MASK]', 'N/A', '']</th>\n",
       "      <td>0.689868</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.642368</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.447105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probs_rescaled_train_queries</th>\n",
       "      <td>0.663263</td>\n",
       "      <td>0.011964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb</th>\n",
       "      <th>test</th>\n",
       "      <th>0</th>\n",
       "      <th>content_free_['[MASK]', 'N/A', '']</th>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">trec</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">test</th>\n",
       "      <th>4</th>\n",
       "      <th>probs_rescaled_train_queries</th>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.032019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th>content_free_['[MASK]', 'N/A', '']</th>\n",
       "      <td>0.466400</td>\n",
       "      <td>0.042998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.052154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.040924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probs_rescaled_train_queries</th>\n",
       "      <td>0.490800</td>\n",
       "      <td>0.049165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      score:accuracy   \n",
       "                                                                                mean   \n",
       "model   dataset eval_split n_shots output_prob_type                                    \n",
       "gpt2-xl agnews  test       0       content_free_['[MASK]', 'N/A', '']       0.689868  \\\n",
       "                                   content_free_['idk']                     0.642368   \n",
       "                                   original_probs                           0.447105   \n",
       "                                   probs_rescaled_train_queries             0.663263   \n",
       "        cb      test       0       content_free_['[MASK]', 'N/A', '']       0.089286   \n",
       "...                                                                              ...   \n",
       "        trec    test       4       probs_rescaled_train_queries             0.469200   \n",
       "                           8       content_free_['[MASK]', 'N/A', '']       0.466400   \n",
       "                                   content_free_['idk']                     0.454000   \n",
       "                                   original_probs                           0.269600   \n",
       "                                   probs_rescaled_train_queries             0.490800   \n",
       "\n",
       "                                                                                 \n",
       "                                                                            std  \n",
       "model   dataset eval_split n_shots output_prob_type                              \n",
       "gpt2-xl agnews  test       0       content_free_['[MASK]', 'N/A', '']  0.000000  \n",
       "                                   content_free_['idk']                0.000000  \n",
       "                                   original_probs                      0.000000  \n",
       "                                   probs_rescaled_train_queries        0.011964  \n",
       "        cb      test       0       content_free_['[MASK]', 'N/A', '']  0.000000  \n",
       "...                                                                         ...  \n",
       "        trec    test       4       probs_rescaled_train_queries        0.032019  \n",
       "                           8       content_free_['[MASK]', 'N/A', '']  0.042998  \n",
       "                                   content_free_['idk']                0.052154  \n",
       "                                   original_probs                      0.040924  \n",
       "                                   probs_rescaled_train_queries        0.049165  \n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_results(root_dir, experiment_name):\n",
    "    score_results = pd.read_csv(os.path.join(root_dir, \"results\", f\"{experiment_name}_results.csv\"), index_col=None)\n",
    "    for column in score_results.columns:\n",
    "        if \"score:\" in column:\n",
    "            score_name = column.split(\":\")[1]\n",
    "            break\n",
    "    return score_results, score_name\n",
    "\n",
    "def table_mean_std(score_results, score, prob_types=None, dataset=None):\n",
    "    score_results = score_results.sort_values([\"model\", \"dataset\", \"eval_split\", \"n_shots\", \"output_prob_type\"])\n",
    "    score_results = score_results.groupby([\"model\", \"dataset\", \"eval_split\", \"n_shots\", \"output_prob_type\"]).agg({\n",
    "        f\"score:{score}\": [\"mean\", \"std\"], \n",
    "    })\n",
    "    if prob_types is not None:\n",
    "        prob_types = [pt for pt in prob_types if pt in score_results.index.get_level_values(\"output_prob_type\").unique()]\n",
    "        score_results = score_results.loc[(slice(None), slice(None), slice(None), slice(None), prob_types), :].sort_index(level=[\"model\", \"dataset\", \"eval_split\", \"n_shots\"])\n",
    "    if dataset is not None:\n",
    "        dataset = [ds for ds in dataset if ds in score_results.index.get_level_values(\"dataset\").unique()]\n",
    "        score_results = score_results.loc[(slice(None), dataset, slice(None), slice(None), slice(None)), :].sort_index(level=[\"model\", \"dataset\", \"eval_split\", \"n_shots\"])\n",
    "    return score_results\n",
    "\n",
    "root_dir = \"./\"\n",
    "experiment = \"gpt2-xl_n100\"\n",
    "# experiment = \"cb\"\n",
    "# experiment = \"gpt3-text-davinci-003_n100\"\n",
    "# prob_types = [\"original_probs\", \"content_free_['idk']\"]\n",
    "prob_types = None\n",
    "# dataset = [\"cb\", \"trec\"]\n",
    "dataset = [\"cb\", \"rte\", \"sst2\", \"trec\", \"agnews\"]\n",
    "score_results, score = read_results(root_dir, experiment)\n",
    "table_mean_std(score_results, score, prob_types=prob_types, dataset=dataset)#.index.get_level_values(\"dataset\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agnews\n",
      "[0.25 0.25 0.25 0.25]\n",
      "[0.25 0.25 0.25 0.25]\n",
      "\n",
      "trec\n",
      "[0.16434336 0.15315481 0.22432135 0.2131328  0.22927366 0.01577403]\n",
      "[0.226 0.162 0.13  0.276 0.188 0.018]\n",
      "\n",
      "cb\n",
      "[0.476 0.064 0.46 ]\n",
      "[0.5        0.08928571 0.41071429]\n",
      "\n",
      "rte\n",
      "[0.49839357 0.50160643]\n",
      "[0.47292419 0.52707581]\n",
      "\n",
      "sst2\n",
      "[0.4783237 0.5216763]\n",
      "[0.50082372 0.49917628]\n",
      "\n",
      "dbpedia\n",
      "[0.07108142 0.07066141 0.0699414  0.07116142 0.07210144 0.07124142\n",
      " 0.07214144 0.06960139 0.07030141 0.07090142 0.07296146 0.07314146\n",
      " 0.07188144 0.07288146]\n",
      "[0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.data import ClassificationDataset\n",
    "\n",
    "datasets = ClassificationDataset.DATASETS\n",
    "for dataset_name in datasets:\n",
    "    dataset = ClassificationDataset(\n",
    "        \"./\",\n",
    "        None,\n",
    "        dataset_name,\n",
    "        n_shot=0,\n",
    "        random_state=None\n",
    "    )\n",
    "    print(dataset_name)\n",
    "    p_train = np.bincount(dataset._data[\"train_labels\"], minlength=len(dataset.label_dict))\n",
    "    p_train = p_train / p_train.sum()\n",
    "    print(p_train)\n",
    "    p_test = np.bincount(dataset._data[\"test_labels\"], minlength=len(dataset.label_dict))\n",
    "    p_test = p_test / p_test.sum()\n",
    "    print(p_test)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
