{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">score:accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>eval_split</th>\n",
       "      <th>n_shots</th>\n",
       "      <th>output_prob_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">gpt2-xl</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">cb</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.389286</td>\n",
       "      <td>0.140834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.163955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.124617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.150785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.539286</td>\n",
       "      <td>0.059761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.560714</td>\n",
       "      <td>0.096660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">trec</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.241200</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>content_free_['idk']</th>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.077504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_probs</th>\n",
       "      <td>0.308800</td>\n",
       "      <td>0.086378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        score:accuracy   \n",
       "                                                                  mean   \n",
       "model   dataset eval_split n_shots output_prob_type                      \n",
       "gpt2-xl cb      test       0       content_free_['idk']       0.196429  \\\n",
       "                                   original_probs             0.321429   \n",
       "                           1       content_free_['idk']       0.389286   \n",
       "                                   original_probs             0.421429   \n",
       "                           4       content_free_['idk']       0.485714   \n",
       "                                   original_probs             0.400000   \n",
       "                           8       content_free_['idk']       0.539286   \n",
       "                                   original_probs             0.560714   \n",
       "        trec    test       0       content_free_['idk']       0.241200   \n",
       "                                   original_probs             0.230800   \n",
       "                           1       content_free_['idk']       0.337600   \n",
       "                                   original_probs             0.308800   \n",
       "\n",
       "                                                                   \n",
       "                                                              std  \n",
       "model   dataset eval_split n_shots output_prob_type                \n",
       "gpt2-xl cb      test       0       content_free_['idk']  0.000000  \n",
       "                                   original_probs        0.000000  \n",
       "                           1       content_free_['idk']  0.140834  \n",
       "                                   original_probs        0.163955  \n",
       "                           4       content_free_['idk']  0.124617  \n",
       "                                   original_probs        0.150785  \n",
       "                           8       content_free_['idk']  0.059761  \n",
       "                                   original_probs        0.096660  \n",
       "        trec    test       0       content_free_['idk']  0.001789  \n",
       "                                   original_probs        0.001789  \n",
       "                           1       content_free_['idk']  0.077504  \n",
       "                                   original_probs        0.086378  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_results(root_dir, experiment_name):\n",
    "    score_results = pd.read_csv(os.path.join(root_dir, \"results\", f\"{experiment_name}_results.csv\"), index_col=None)\n",
    "    for column in score_results.columns:\n",
    "        if \"score:\" in column:\n",
    "            score_name = column.split(\":\")[1]\n",
    "            break\n",
    "    return score_results, score_name\n",
    "\n",
    "def table_mean_std(score_results, score, prob_types):\n",
    "    score_results = score_results.sort_values([\"model\", \"dataset\", \"eval_split\", \"n_shots\", \"output_prob_type\"])\n",
    "    score_results = score_results.groupby([\"model\", \"dataset\", \"eval_split\", \"n_shots\", \"output_prob_type\"]).agg({\n",
    "        f\"score:{score}\": [\"mean\", \"std\"], \n",
    "    })\n",
    "    if prob_types is not None:\n",
    "        score_results = score_results.loc[(slice(None), slice(None), slice(None), slice(None), prob_types), :].sort_index(level=[\"model\", \"dataset\", \"eval_split\", \"n_shots\"])\n",
    "    return score_results\n",
    "\n",
    "root_dir = \"./\"\n",
    "experiment = \"gpt2-xl_n100\"\n",
    "score_results, score = read_results(root_dir, experiment)\n",
    "table_mean_std(score_results, score, prob_types=[\"original_probs\", \"content_free_['idk']\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agnews\n",
      "[0.25 0.25 0.25 0.25]\n",
      "[0.25 0.25 0.25 0.25]\n",
      "\n",
      "trec\n",
      "[0.16434336 0.15315481 0.22432135 0.2131328  0.22927366 0.01577403]\n",
      "[0.226 0.162 0.13  0.276 0.188 0.018]\n",
      "\n",
      "cb\n",
      "[0.476 0.064 0.46 ]\n",
      "[0.5        0.08928571 0.41071429]\n",
      "\n",
      "rte\n",
      "[0.49839357 0.50160643]\n",
      "[0.47292419 0.52707581]\n",
      "\n",
      "sst2\n",
      "[0.4783237 0.5216763]\n",
      "[0.50082372 0.49917628]\n",
      "\n",
      "dbpedia\n",
      "[0.07108142 0.07066141 0.0699414  0.07116142 0.07210144 0.07124142\n",
      " 0.07214144 0.06960139 0.07030141 0.07090142 0.07296146 0.07314146\n",
      " 0.07188144 0.07288146]\n",
      "[0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.data import ClassificationDataset\n",
    "\n",
    "datasets = ClassificationDataset.DATASETS\n",
    "for dataset_name in datasets:\n",
    "    dataset = ClassificationDataset(\n",
    "        \"./\",\n",
    "        None,\n",
    "        dataset_name,\n",
    "        n_shot=0,\n",
    "        random_state=None\n",
    "    )\n",
    "    print(dataset_name)\n",
    "    p_train = np.bincount(dataset._data[\"train_labels\"], minlength=len(dataset.label_dict))\n",
    "    p_train = p_train / p_train.sum()\n",
    "    print(p_train)\n",
    "    p_test = np.bincount(dataset._data[\"test_labels\"], minlength=len(dataset.label_dict))\n",
    "    p_test = p_test / p_test.sum()\n",
    "    print(p_test)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
